# Qwen3:8b - Nosana Endpoint
# Note baseURL for Ollama needs to be appended with `/api`
OLLAMA_API_URL=https://3yt39qx97wc9hqwwmylrphi4jsxrngjzxnjakkybnxbw.node.k8s.prd.nos.ci/api
MODEL_NAME_AT_ENDPOINT=qwen3:8b

# Qwen3:8b - Nosana Endpoint
# Note baseURL for Ollama needs to be appended with `/api`
# OLLAMA_API_URL=https://<nosana-url-id>.node.k8s.prd.nos.ci/api
# MODEL_NAME_AT_ENDPOINT=qwen3:8b

# Qwen3:8b - LocalHost - Local Development
# https://ollama.com/download
# Note baseURL for Ollama needs to be appended with `/api`
# `ollama pull qwen3:0.6b`
# `ollama serve`
# OLLAMA_API_URL=http://127.0.0.1:11434/api
# MODEL_NAME_AT_ENDPOINT=qwen3:0.6b

# OpenAI - Uncomment and add apikey to use OpenAI
# Uncomment the corresponding line in `src/mastra/agents/index.ts` to use OpenAI
# OPENAI_API_KEY=

# Supabase Configuration
NEXT_PUBLIC_SUPABASE_URL=
NEXT_PUBLIC_SUPABASE_ANON_KEY=
SUPABASE_SERVICE_ROLE_KEY=

# Cache Configuration (LRU)
# Size in number of items
CACHE_SIZE=1000
# TTL in seconds (default 24 hours)
CACHE_TTL=86400

# Logging Configuration
# Levels: fatal, error, warn, info, debug, trace
LOG_LEVEL=info
